{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7bd8b500-1dfe-4862-b973-affd12f9cdf5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Chapter 7: Structured Streaming in Spark Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cddfa038-1869-4608-997f-e0b1512b1092",
     "showTitle": true,
     "title": "Handling Schema Evolution"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "java.lang.IllegalStateException: Failed to init Scala kernel\n",
       "\tat com.databricks.backend.daemon.driver.ScalaJupyterDriverLocal.executeInitCommand(ScalaJupyterDriverLocal.scala:297)\n",
       "\tat com.databricks.backend.daemon.driver.ScalaJupyterDriverLocal.initSparkSession(ScalaJupyterDriverLocal.scala:496)\n",
       "\tat com.databricks.backend.daemon.driver.ScalaJupyterDriverLocal.repl(ScalaJupyterDriverLocal.scala:518)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$36(DriverLocal.scala:1115)\n",
       "\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:45)\n",
       "\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:103)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$24(DriverLocal.scala:1106)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:87)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:87)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:1043)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:768)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:760)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$3(DriverWrapper.scala:800)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:72)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionTags(DriverWrapper.scala:72)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.recordOperationWithResultTags(DriverWrapper.scala:72)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:800)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:667)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:712)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$runInnerLoop$1(DriverWrapper.scala:542)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:72)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:542)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:464)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:290)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "IllegalStateException: Failed to init Scala kernel"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "java.lang.IllegalStateException: Failed to init Scala kernel",
        "\tat com.databricks.backend.daemon.driver.ScalaJupyterDriverLocal.executeInitCommand(ScalaJupyterDriverLocal.scala:297)",
        "\tat com.databricks.backend.daemon.driver.ScalaJupyterDriverLocal.initSparkSession(ScalaJupyterDriverLocal.scala:496)",
        "\tat com.databricks.backend.daemon.driver.ScalaJupyterDriverLocal.repl(ScalaJupyterDriverLocal.scala:518)",
        "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$36(DriverLocal.scala:1115)",
        "\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:45)",
        "\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:103)",
        "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$24(DriverLocal.scala:1106)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:87)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:87)",
        "\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:1043)",
        "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:768)",
        "\tat scala.util.Try$.apply(Try.scala:213)",
        "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:760)",
        "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$3(DriverWrapper.scala:800)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:72)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionTags(DriverWrapper.scala:72)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.backend.daemon.driver.DriverWrapper.recordOperationWithResultTags(DriverWrapper.scala:72)",
        "\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:800)",
        "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:667)",
        "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:712)",
        "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$runInnerLoop$1(DriverWrapper.scala:542)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.backend.daemon.driver.DriverWrapper.withAttributionContext(DriverWrapper.scala:72)",
        "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:542)",
        "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:464)",
        "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:290)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%scala\n",
    "val stream = spark.readStream\n",
    "  .format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .schema(initialSchema)\n",
    "  .load(\"data/input\")\n",
    "\n",
    "val mergedStream = stream\n",
    "  .selectExpr(\"col1\", \"col2\", \"new_col AS col3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22e49e90-52fe-4b66-b4c5-af0b57945992",
     "showTitle": true,
     "title": "Stream-Stream Joins"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1450182024496131>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43memployeedf\u001B[49m\u001B[38;5;241m.\u001B[39mjoin(salarydf, col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124memployeedf.employeeID\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m==\u001B[39mcol(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msalarydf.employeeSalaryID\u001B[39m\u001B[38;5;124m\"\u001B[39m))\u001B[38;5;241m.\u001B[39mfilter(\u001B[38;5;241m~\u001B[39misnull(col(department)))\u001B[38;5;241m.\u001B[39msum(col(department))\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'employeedf' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-1450182024496131>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43memployeedf\u001B[49m\u001B[38;5;241m.\u001B[39mjoin(salarydf, col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124memployeedf.employeeID\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m==\u001B[39mcol(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msalarydf.employeeSalaryID\u001B[39m\u001B[38;5;124m\"\u001B[39m))\u001B[38;5;241m.\u001B[39mfilter(\u001B[38;5;241m~\u001B[39misnull(col(department)))\u001B[38;5;241m.\u001B[39msum(col(department))\n\n\u001B[0;31mNameError\u001B[0m: name 'employeedf' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'employeedf' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%scala\n",
    "val stream1 = spark.readStream.format(\"kafka\")\n",
    "  .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n",
    "  .option(\"subscribe\", \"topic1\")\n",
    "  .load()\n",
    "\n",
    "val stream2 = spark.readStream.format(\"kafka\")\n",
    "  .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n",
    "  .option(\"subscribe\", \"topic2\")\n",
    "  .load()\n",
    "\n",
    "val joinedStream = stream1.join(stream2, \"common_key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "391a8356-8f32-441d-9f2c-f5a6a7a285f9",
     "showTitle": true,
     "title": "Stream-Static Joins"
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "val stream = spark.readStream.format(\"kafka\")\n",
    "  .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n",
    "  .option(\"subscribe\", \"topic\")\n",
    "  .load()\n",
    "\n",
    "val staticData = spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .load(\"data/static_data.csv\")\n",
    "\n",
    "val enrichedStream = stream.join(staticData, \"common_key\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 969987236417588,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Chapter 7 Code",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
